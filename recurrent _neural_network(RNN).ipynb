{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hey guys, we are gonna discuss RNN in this notebook\n",
    "A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition[4] or speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN is essentially an FNN but with a hidden layer (non-linear output) that passes on information to the next FNN\n",
    "* Compared to an FNN, we've one additional set of weight and bias that allows information to flow from one FNN to another FNN sequentially that allows time-dependency.\n",
    "* The diagram below shows the only difference between an FNN and a RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one layered RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./data/rnn0-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two layered RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./data/rnn0-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps(here we are giving images of 28*28 pixels)\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* 1 Hidden layer\n",
    "* ReLU Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./data/rnn2n.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:56, 176878.63it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_dataset = datasets.MNIST(root = './data',\n",
    "                                   train = True,\n",
    "                                   transform = transforms.ToTensor(),download = True)\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(root = './data',\n",
    "                                   train = False,\n",
    "                                   transform = transforms.ToTensor(),download = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.shape, train_dataset.train_data.shape)\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters/(len(train_dataset)/batch_size) ) + 3\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         shuffle = True, \n",
    "                         batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         shuffle = True, \n",
    "                         batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A: 1 hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$\n",
    "h_{t} = tanh(W_{ih}x_{t} + b_{ih} + W_{hh}h_{t - 1} + b_{hh})\n",
    "$$\n",
    "where $h_{t}$ is the hidden state at time t, $x_{t}$ is the input at time t, and $h_{(t-1)}$ is the hidden state of the previous layer at time t-1 or the initial hidden state at time 0. If nonlinearity is 'relu', then ReLU is used instead of $tanh$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paramters for the RNN model\n",
    "* input_dim: fisrt layer num nodes\n",
    "* output_dim:  last layer num nodes\n",
    "* hidden_dim: num of nodes in the hidden layer\n",
    "* layer_dim:  layer_dim â€“ Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "* seq_dim: number of sequences in a sample, for e.g: number of wards in a sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNmodel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layer_dim):\n",
    "        super(RNNmodel,self).__init__()\n",
    "        \n",
    "        # hidden dimesnion\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # numeber of RNN stacked layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        \n",
    "        # build rnn model\n",
    "        # normally input and output tensor from a layer is in the shape (channel_dim(num of channels), batch_dim, num_feature) like (3, 128, 28, 28)\n",
    "        # but with batch_first = True, input and output tensor will be of the shape (batch_dim, channel_dim, num_features) like (128, 3, 28, 28)\n",
    "        # batch_dim = num of samples in a batch\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, \n",
    "                         layer_dim, batch_first = True, \n",
    "                         nonlinearity = 'relu')\n",
    "        \n",
    "        # readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # rnn needs to inputs: output from the pervious iteration(called the hidden state(ht)) and input for time t(xt)\n",
    "        # so for the initial iteration, we have to initialize inital state(h0), manually\n",
    "        \n",
    "        # initializing the inital state\n",
    "        # (layer_dim, batch_size, hidden_dim) ==> (1, 128, 100)\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "#         print(x.shape, \"before reshape\")\n",
    "        x = x.view(x.shape[0], 28, 28)\n",
    "#         print(x.shape, h0.shape)\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "        \n",
    "        # output.size = (batch_dim ,seq_len, output_dim) ==> (128, 28, 10)\n",
    "        # this output matrix contain the output of each time step\n",
    "        # but we need the output for the last time step\n",
    "        # therefore\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # out_size() ==> (100, 10)\n",
    "        return out\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initiatlizing model paramters and citerion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "num_epochs = 3000\n",
    "\n",
    "model = RNNmodel(input_dim, hidden_dim, output_dim, layer_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to hidden weights(Wih):  torch.Size([100, 28])\n",
      "hidden to hidden weights(Whh):  torch.Size([100, 100])\n",
      "Input to hidden bias(Bih):  torch.Size([100])\n",
      "Hidden to hidden bias(Bhh):  torch.Size([100])\n",
      "Hidden to output weights(Who):  torch.Size([10, 100])\n",
      "Hidden to output bias(Bho):  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input to hidden weights(Wih): \", list(model.parameters())[0].shape)\n",
    "print(\"hidden to hidden weights(Whh): \", list(model.parameters())[1].shape)\n",
    "print(\"Input to hidden bias(Bih): \", list(model.parameters())[2].shape)\n",
    "print(\"Hidden to hidden bias(Bhh): \", list(model.parameters())[3].shape)\n",
    "print(\"Hidden to output weights(Who): \", list(model.parameters())[4].shape)\n",
    "print(\"Hidden to output bias(Bho): \", list(model.parameters())[5].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================epoch num: 0=======================\n",
      "==========================epoch num: 1=======================\n",
      "Iteration: 500. Loss: 0.025200678035616875. Accuracy: 97.0999984741211\n",
      "==========================epoch num: 2=======================\n",
      "Iteration: 1000. Loss: 0.055494390428066254. Accuracy: 96.91999816894531\n",
      "==========================epoch num: 3=======================\n",
      "Iteration: 1500. Loss: 0.033629078418016434. Accuracy: 97.1500015258789\n",
      "==========================epoch num: 4=======================\n",
      "Iteration: 2000. Loss: 0.049652520567178726. Accuracy: 97.01000213623047\n",
      "==========================epoch num: 5=======================\n",
      "Iteration: 2500. Loss: 0.05371534824371338. Accuracy: 97.3499984741211\n"
     ]
    }
   ],
   "source": [
    "# num of time steps(number of times to unroll)\n",
    "seq_dim = 28\n",
    "num_epochs = 6\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"==========================epoch num: {}=======================\".format(epoch))\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # clear gradients in the optimizer object \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # getting  gradients of loss w.r.t weights\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        \n",
    "        if iter%500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = images.requires_grad_()\n",
    "                \n",
    "                outputs = model.forward(images)\n",
    "                # it doesnt make much differnce if we use or not use softmax function here\n",
    "                outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "                \n",
    "            accuracy = 100*(correct/total)\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python37764bitmyenvconda823dfb8e79a54b2babc4116ecd4d023d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
