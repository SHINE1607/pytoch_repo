{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding SummaryÂ¶\n",
    "* Valid Padding (No Padding)<br>\n",
    "    Output size < Input Size\n",
    "* Same Padding (Zero Padding)<br>\n",
    "    Output size = Input Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimension calculation\n",
    "* out_dim  $$\n",
    "O = \\frac{W - K + 2P}{S}  + 1\\\\\n",
    "$$\n",
    "\n",
    "* O:output height/width\n",
    "* W:input height/length\n",
    "* K: filter size(kernel size)\n",
    "* P: padding =$$\n",
    "P = \\frac{K - 1}{2}\\\\\n",
    "$$\n",
    "* S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [01:41, 97657.12it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_dataset = datasets.MNIST(root = './data',\n",
    "                                   train = True,\n",
    "                                   transform = transforms.ToTensor(),download = True)\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(root = './data',\n",
    "                                   train = False,\n",
    "                                   transform = transforms.ToTensor(),download = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.shape, train_dataset.train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters/(len(train_dataset)/batch_size) ) + 3\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                         shuffle = True, \n",
    "                         batch_size = batch_size)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(train_dataset,\n",
    "                         shuffle = True, \n",
    "                         batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolution calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output calculation for convolution layer\n",
    "$$ \n",
    "O = \\frac{W - K + 2P}{S}  + 1\\\\\n",
    "$$\n",
    "* K(kernel_size) = 5(5*5)\n",
    "* S(stride) = 1\n",
    "* P = (k - 1)/2 = 2\n",
    "\n",
    "#### output dimension for pooling layer\n",
    "$$ \n",
    "O = \\frac{W - K}{S} + 1\\\\\n",
    "$$\n",
    "* kernel size = 2\n",
    "* stride = kernel size (by defualt in pytorch) = 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \n",
    "* output of the convolution layer\n",
    "$$\n",
    "O = \\frac{28 - 5 + 2*2}{1} + 1\\\\ = 28\n",
    "$$\n",
    "\n",
    "* output of the pooling layer\n",
    "$$\n",
    "O = \\frac{28 - 2}{2} + 1\\\\ = 14\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/cnn10-2n.png\" alt=\"image info\" />\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### layer wise distribution\n",
    "input layer  ==> conv layer   ==> maxpool layer ==> conv layer   ==> maxpool layer ==> output layer\n",
    "(1, 28, 28)  ==> (16, 28, 28) ==> (16, 14, 14)  ==> (32, 14, 14) ==> (32, 7, 7)    ==> (10, 1)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1: with padding(same padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        super(CNN_model, self).__init__()\n",
    "        \n",
    "        # layer1: convolutional layer \n",
    "        self.cnn1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # layer2: max pooling\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size  = 2)\n",
    "        \n",
    "        # layer3: convolutional layer \n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # layer4: max pooling\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size  = 2)\n",
    "        \n",
    "        # output layer: Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10) \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        \n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    \n",
    "model = CNN_model()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv layer1 kernel:  torch.Size([16, 1, 5, 5])\n",
      "maxpooling1:  torch.Size([16])\n",
      "conv layer2 kernel:  torch.Size([32, 16, 5, 5])\n",
      "maxpooling2:  torch.Size([32])\n",
      "output linear:  torch.Size([10, 1568])\n"
     ]
    }
   ],
   "source": [
    "#### cheking  model parameters\n",
    "print(\"conv layer1 kernel: \", list(model.parameters())[0].shape)\n",
    "print(\"maxpooling1: \", list(model.parameters())[1].shape)\n",
    "print(\"conv layer2 kernel: \", list(model.parameters())[2].shape)\n",
    "print(\"maxpooling2: \", list(model.parameters())[3].shape)\n",
    "print(\"output linear: \", list(model.parameters())[4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instantiating the loss fucntion and the optimizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate )\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2: no padding(valid padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./data/cnn10-6n.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### layer wise distribution\n",
    "input-layer => conv layer => maxpool    => conv layer => maxpool  => output layer\n",
    "(28,28)     => (16,24,24) => (16,12,12) => (32,8,8)   => (32,4,4) => (10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        super(CNN_model, self).__init__()\n",
    "        \n",
    "        # layer1: convolutional layer \n",
    "        self.cnn1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # layer2: max pooling\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size  = 2)\n",
    "        \n",
    "        # layer3: convolutional layer \n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # layer4: max pooling\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size  = 2)\n",
    "        \n",
    "        # output layer: Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*4*4, 10) \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ##### conv  layer 1 ##### \n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        ######################### \n",
    "        \n",
    "        ##### max pool 1 ##### \n",
    "        out = self.maxpool1(out)\n",
    "        ######################### \n",
    "        \n",
    "        ##### conv  layer 2 #####         \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        ######################### \n",
    "\n",
    "        ##### max pool 2 ##### \n",
    "        out = self.maxpool2(out)\n",
    "        #########################\n",
    "        \n",
    "        # reshaping the output\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        ##### output layer: linear ##### \n",
    "        out = self.fc1(out)\n",
    "        ################################\n",
    "\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    \n",
    "model = CNN_model()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model traning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.09718340635299683. Accuracy: 97.15333557128906\n",
      "Iteration: 1000. Loss: 0.13340891897678375. Accuracy: 97.33833312988281\n",
      "Iteration: 1500. Loss: 0.08473212271928787. Accuracy: 97.3933334350586\n",
      "Iteration: 2000. Loss: 0.17217475175857544. Accuracy: 97.34667205810547\n",
      "Iteration: 2500. Loss: 0.13855279982089996. Accuracy: 97.45833587646484\n",
      "Iteration: 3000. Loss: 0.062202829867601395. Accuracy: 97.77833557128906\n",
      "Iteration: 3500. Loss: 0.04042651876807213. Accuracy: 97.76166534423828\n",
      "Iteration: 4000. Loss: 0.06984707713127136. Accuracy: 97.84833526611328\n"
     ]
    }
   ],
   "source": [
    "iter = 0;\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "#         no need to reshape images for convluation network\n",
    "        \n",
    "        images = images.requires_grad_()\n",
    "        # clearing the optimizer gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get the output\n",
    "        output = model(images)\n",
    "        \n",
    "        # calculate loss: softmax => cross entropy loss\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # getting gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating the weights with \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        # validating the current model\n",
    "        if iter%500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = images.requires_grad_()\n",
    "                \n",
    "                outputs = model.forward(images)\n",
    "                # it doesnt make much differnce if we use or not use softmax function here\n",
    "                outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "                \n",
    "            accuracy = 100*(correct/total)\n",
    "            \n",
    "\n",
    "#           Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python37764bitmyenvconda823dfb8e79a54b2babc4116ecd4d023d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
